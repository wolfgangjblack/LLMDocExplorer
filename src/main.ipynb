{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c21a2a68",
   "metadata": {},
   "source": [
    "# Interactive LLM Notebook\n",
    "\n",
    "this notebook provides the front end for interacting with the context-given LLM. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6dd8796",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a02fd139",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY'] = \n",
    "##need to load this first... before we load in the config... need to think about HOW this should work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c38dbbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Eventually make this something to be loaded \n",
    "config = {\n",
    "    'basedir': '../vectorstore/',\n",
    "    'retrain_str': False,\n",
    "    'persist_dir': '../vectorstore/chroma/',\n",
    "    'datadir': '../../journals/',\n",
    "    'text_splitter': RecursiveCharacterTextSplitter(\n",
    "                            chunk_size = 1500,\n",
    "                            chunk_overlap = 150,\n",
    "                            separators=['<|endoftext|>',\"\\n\\n\", \"\\n\", \"\\n(.+?)\\n\",\"(?<=\\. )\", \" \", \"\"]\n",
    "                                            ),\n",
    "    'embeddings':OpenAIEmbeddings(),\n",
    "    'allowed_special_kwargs': '<|endoftext|>',\n",
    "    'llm': ChatOpenAI(model_name='gpt-3.5-turbo', temperature=0), }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c22d59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils import retrieve_context_vectordb, get_conversational_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70f0e4db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading vectordb\n"
     ]
    }
   ],
   "source": [
    "config['retriever'] = retrieve_context_vectordb(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "080dc312",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = get_conversational_llm(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "09495695",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'who wrote the paper about fluid mechanics and deep learning?'\n",
    "chat_history = []\n",
    "result = qa({\"question\": question, \"chat_history\": chat_history})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5def3833",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'who wrote the paper about fluid mechanics and deep learning?',\n",
       " 'chat_history': [],\n",
       " 'answer': 'The paper titled \"A review on deep reinforcement learning for fluid mechanics: An update\" was written by J. Viquerat, P. Meliga, A. Larcher, and E. Hachem.',\n",
       " 'source_documents': [Document(page_content='A review on deep reinforcement learning\\nfor fluid mechanics: An update\\nCite as: Phys. Fluids 34, 111301 (2022); doi: 10.1063/5.0128446\\nSubmitted: 28 September 2022 .Accepted: 1 November 2022 .\\nPublished Online: 17 November 2022\\nJ.Viquerat,a)\\nP.Meliga,b)A.Larcher,c)\\nand E. Hachemd)\\nAFFILIATIONS\\nMINES Paristech, CEMEF PSL Research University, 06904 Sophia Antipolis, France\\na)Author to whom correspondence should be addressed: jonathan.viquerat@mines-paristech.fr\\nb)philippe.meliga@mines-paristech.fr\\nc)aurelien.larcher@mines-paristech.fr\\nd)elie.hachem@mines-paristech.fr\\nABSTRACT\\nIn the past couple of years, the interest of the ﬂuid mechanics community for deep reinforcement learning techniques has increased at fast\\npace, leading to a growing bibliography on the topic. Due to its ability to solve complex decision-making problems, deep reinforcement learn-ing has especially emerged as a valuable tool to perform ﬂow control, but recent publications also advertise the great potential for other appli-\\ncations, such as shape optimization or microﬂuidics. The present work proposes an exhaustive review of the existing literature and is a', metadata={'source': '../../journals/2022 Meliga A review on deep RL for fluid mechanics.pdf', 'page': 1}),\n",
       "  Document(page_content='Phys. Fluids 34, 111301 (2022); https://doi.org/10.1063/5.0128446 34, 111301\\n© 2022 Author(s).A review on deep reinforcement learning for\\nfluid mechanics: An update  \\nCite as: Phys. Fluids 34, 111301 (2022); https://doi.org/10.1063/5.0128446\\nSubmitted: 28 September 2022 • Accepted: 01 November 2022 • Published Online: 17 November 2022\\n J. Viquerat , P. Meliga , \\n A. Larcher , et al.\\nCOLLECTIONS\\n This paper was selected as Featured\\nARTICLES YOU MAY BE INTERESTED IN\\nKitchen flows: Making science more accessible, affordable, and curiosity driven\\nPhysics of Fluids 34, 110401 (2022); https://doi.org/10.1063/5.0131565\\nDRLinFluids: An open-source Python platform of coupling deep reinforcement learning and\\nOpenFOAM\\nPhysics of Fluids 34, 081801 (2022); https://doi.org/10.1063/5.0103113\\nDevelopment of a scattering model for diatomic gas–solid surface interactions by an\\nunsupervised machine learning approach\\nPhysics of Fluids 34, 117122 (2022); https://doi.org/10.1063/5.0110117', metadata={'source': '../../journals/2022 Meliga A review on deep RL for fluid mechanics.pdf', 'page': 0}),\n",
       "  Document(page_content='review on deep reinforcement learning for ﬂuid mechanics,” Comput. Fluids\\n225, 104973 (2021).\\n19J. Rabault, F. Ren, and W. Zhang et al., “Deep reinforcement learning in ﬂuid\\nmechanics: A promising method for both active ﬂow control and shape opti-\\nmization,” J. Hydrodyn. 32, 234–246 (2020).\\n20R. S. Sutton and A. G. Barto, Reinforcement Learning: An Introduction (MIT\\nPress, Cambridge, 2018).\\n21R. Bellman and S. E. Dreyfus, Applied Dynamic Programming (Princeton\\nUniversity Press Princeton, 1962).\\n22R. J. Williams, “Simple statistical gradient-following algorithms for connection-ist reinforcement learning,” Mach. Learn. 8(3), 229–256 (1992).\\n23K. Hornik, M. Stinchcombe, and H. White, “Multilayer feedforward networks\\nare universal approximators,” Neural Networks 2(5), 359–366 (1989).\\n24H. T. Siegelmann and E. D. Sontag, “On the computational power of neural\\nnets,” J. Comput. Syst. Sci. 50(1), 132–150 (1995).\\n25I. Goodfellow, Y. Bengio, and A. Courville, The Deep Learning Book (MIT\\nPress, 2017).\\n26V. Mnih, K. Kavukcuoglu, D. Silver, A. A. Rusu, J. Veness, M. G. Bellemare, A.\\nGraves, M. Riedmiller, A. K. Fidjeland, G. Ostrovski, S. Petersen, C. Beattie, A.\\nSadik, I. Antonoglou, H. King, D. Kumaran, D. Wierstra, S. Legg, and D.Hassabis, “Human-level control through deep reinforcement learning,” Nature\\n518, 529 (2015).\\n27T. Schaul, J. Quan, I. Antonoglou, and D. Silver, “Prioritized experience', metadata={'source': '../../journals/2022 Meliga A review on deep RL for fluid mechanics.pdf', 'page': 18}),\n",
       "  Document(page_content='in the community, and the sustained commitment from the machine\\nlearning community that has allowed concurrently expanding the\\nscope from computationally inexpensive, low-dimensional reductions\\nof the underlying ﬂuid dynamics to complex Navier–Stokes systems,\\nall the way to experimental setups.\\nThe present review proposes a six-year perspective of deep rein-\\nforcement learning applied to ﬂuid ﬂow problems, in the context of\\nboth numerical and experimental environments. It is intended as a\\nfollow-up to our ﬁrst review released as a pre-print in 2019,18which\\nwas followed in 2020 by a short review from another group of\\nauthors, focused on drag reduction and shape optimization prob-\\nlems.19To the best of the authors’ knowledge, those are the only\\nother similar initiatives preceding this one that are also featured in\\nFig. 1 for the sake of completeness. In practice, only contributions\\nfocusing on the application of deep reinforcement learning techni-\\nques (not machine learning in a broader sense) to ﬂuid dynamical\\nFIG. 1. Timeline of recent publications on deep reinforcement learning for ﬂuid dynamics. Colors indicate different ﬁelds of application. Please note that we retain here the date\\nof the ﬁrst pre-print publication, and not that of ﬁnal publication in peer-review journals. Indeed, the fast-paced evolution of the deep reinforcem ent learning community brings', metadata={'source': '../../journals/2022 Meliga A review on deep RL for fluid mechanics.pdf', 'page': 2})],\n",
       " 'generated_question': 'who wrote the paper about fluid mechanics and deep learning?'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5dd449d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
